{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMz7lZ8+oEj7hb39Ax8btaK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adampotton/Cognitive_AI_CW/blob/main/Q2A_LSTM_BI_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adpating the LSTM model architecture to tackle sparsity"
      ],
      "metadata": {
        "id": "sXVSJrSC5bzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/neurogym/neurogym.git\n",
        "%cd neurogym/\n",
        "! pip install -e ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3gn4uXo2PPtk",
        "outputId": "2cb94321-ab83-4696-b5e4-3f5a11645c19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'neurogym'...\n",
            "remote: Enumerating objects: 11100, done.\u001b[K\n",
            "remote: Counting objects: 100% (1002/1002), done.\u001b[K\n",
            "remote: Compressing objects: 100% (106/106), done.\u001b[K\n",
            "remote: Total 11100 (delta 928), reused 896 (delta 896), pack-reused 10098 (from 1)\u001b[K\n",
            "Receiving objects: 100% (11100/11100), 8.17 MiB | 6.93 MiB/s, done.\n",
            "Resolving deltas: 100% (8333/8333), done.\n",
            "/content/neurogym\n",
            "Obtaining file:///content/neurogym\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from neurogym==0.0.2) (1.26.4)\n",
            "Collecting gym<0.25,>=0.20.0 (from neurogym==0.0.2)\n",
            "  Downloading gym-0.24.1.tar.gz (696 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m696.4/696.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from neurogym==0.0.2) (3.8.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym<0.25,>=0.20.0->neurogym==0.0.2) (3.1.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym<0.25,>=0.20.0->neurogym==0.0.2) (0.0.8)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym==0.0.2) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym==0.0.2) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym==0.0.2) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym==0.0.2) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym==0.0.2) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym==0.0.2) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym==0.0.2) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->neurogym==0.0.2) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->neurogym==0.0.2) (1.16.0)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.24.1-py3-none-any.whl size=793125 sha256=5946cd4346502d8cd27c6d523570a1920f3e60648672fdef395e44e13cd261ee\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/fb/19/388995b88cb551717a8dff40c889172cd12fadf994216a0a22\n",
            "Successfully built gym\n",
            "Installing collected packages: gym, neurogym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "  Running setup.py develop for neurogym\n",
            "Successfully installed gym-0.24.1 neurogym-0.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4RPIsY6LowX",
        "outputId": "70e171bc-f7bf-4e7f-d5eb-3786cc5c336c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: Gym version v0.24.1 has a number of critical issues with `gym.make` such that environment observation and action spaces are incorrectly evaluated, raising incorrect errors and warning . It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:396: UserWarning: \u001b[33mWARN: The `registry.all` method is deprecated. Please use `registry.values` instead.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ],
      "source": [
        "import neurogym as ngym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define a simple LSTM model"
      ],
      "metadata": {
        "id": "5xqGhnoAk1Gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_lstm_layers = 2):\n",
        "        super(LSTMNet, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_lstm_layers) # n LSTM layers\n",
        "        self.fc = nn.Linear(hidden_size, output_size) # Fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_output, _ = self.lstm(x)\n",
        "        out = self.fc(lstm_output)\n",
        "        return out, lstm_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvUHo7Q4O0mZ",
        "outputId": "df807583-eb7e-4e27-d8da-e632a85d1e2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating dataset and adjusting parameters"
      ],
      "metadata": {
        "id": "1xE2ARNnlcXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'dt': 200, # Timestep parameter\n",
        "    'hidden_size': 32, # Hidden size for your LSTM\n",
        "    'batch_size': 16, # Batch size for training\n",
        "    'seq_len': 100, # Sequence length for input data\n",
        "    'envid': 'ReadySetGo-v0', # Task name\n",
        "    'gain': 2, # Custom gain\n",
        "    'prod_margin': 10, # Custom production margin\n",
        "}\n",
        "\n",
        "env_kwargs = {\n",
        "    'dt': config['dt'], # Assing timestep parameter\n",
        "    'gain': config['gain'],  # Controls the measure that the agent has to produce\n",
        "    'prod_margin': config['prod_margin'], # Controls the interval around the ground truth production time within which the agent receives proportional reward\n",
        "}\n",
        "config['env_kwargs'] = env_kwargs\n",
        "\n",
        "dataset = ngym.Dataset(config['envid'], env_kwargs=config['env_kwargs'], batch_size=config['batch_size'], seq_len=config['seq_len']) # Generate dataset\n",
        "env = dataset.env\n",
        "\n",
        "inputs, target = dataset() # Assing inputs and targets\n",
        "inputs = torch.from_numpy(inputs).type(torch.float)\n",
        "\n",
        "input_size = env.observation_space.shape[0] # Find dimensions for data\n",
        "output_size = env.action_space.n\n",
        "\n",
        "print('Input has shape (SeqLen, Batch, Dim) =', inputs.shape)\n",
        "print('Target has shape (SeqLen, Batch) =', target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEqrXBuGlbO6",
        "outputId": "1a1b2309-7f2a-4729-8d12-9289c8532871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input has shape (SeqLen, Batch, Dim) = torch.Size([100, 16, 3])\n",
            "Target has shape (SeqLen, Batch) = (100, 16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:69: UserWarning: \u001b[33mWARN: Agent's minimum action space value is -infinity. This is probably too low.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:73: UserWarning: \u001b[33mWARN: Agent's maximum action space value is infinity. This is probably too high\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ],
      "metadata": {
        "id": "77PBTEEOlxQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iter_steps = 1000 # Training loops\n",
        "report_freq = 100 # How often a report on is returned\n",
        "\n",
        "net = LSTMNet(input_size, config['hidden_size'], output_size, num_lstm_layers = 1) # Create an instance of the LSTM\n",
        "\n",
        "def train_model(net, dataset, iter_steps, report_freq, l1_beta):\n",
        "\n",
        "    optimizer = optim.AdamW(net.parameters(), lr=0.01) # AdamW optimiser\n",
        "    criterion = nn.CrossEntropyLoss() # Loss funciton\n",
        "\n",
        "    running_loss = 0\n",
        "    running_acc = 0\n",
        "    start_time = time.time() # Start training timer\n",
        "\n",
        "    for i in range(iter_steps): # Loop over training batches\n",
        "        inputs, labels = dataset() # Generate a set of data\n",
        "        inputs = torch.from_numpy(inputs).type(torch.float)\n",
        "        labels = torch.from_numpy(labels.flatten()).type(torch.long)\n",
        "\n",
        "        optimizer.zero_grad() # Reset gradients\n",
        "        output, _ = net(inputs)\n",
        "        output = output.view(-1, output_size)\n",
        "\n",
        "        loss = criterion(output, labels) # Loss function\n",
        "        loss.backward()\n",
        "        optimizer.step()  # Update\n",
        "\n",
        "        batch_acc = (torch.argmax(output, dim=1) == labels).sum().item() / labels.shape[0] # Current batch accuracy\n",
        "        running_loss += loss.item()\n",
        "        running_acc += batch_acc\n",
        "\n",
        "        if i % report_freq == report_freq - 1:\n",
        "            running_loss /= report_freq\n",
        "            running_acc /= report_freq  # average accuracy over the last 100 batches\n",
        "            print('Step {}, Loss {:0.4f}, Accuracy {:0.4f}, Time {:0.1f}s'.format(\n",
        "                i+1, running_loss, running_acc, time.time() - start_time))\n",
        "            running_loss = 0 # Reset metrics for next report\n",
        "            running_acc = 0\n",
        "    return net\n",
        "\n",
        "net = train_model(net, dataset, iter_steps, report_freq, l1_beta) # Call the training function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "milzVKfVSmQT",
        "outputId": "4dbca0bd-4601-4a51-835d-e6090afd8279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.1633,  0.0014,  0.0817],\n",
            "        [-0.0423,  0.0162, -0.0959],\n",
            "        [ 0.0664,  0.1177,  0.0029],\n",
            "        [ 0.1030, -0.1564,  0.0172],\n",
            "        [-0.0867,  0.0422,  0.0886],\n",
            "        [ 0.0344, -0.0089, -0.1667],\n",
            "        [-0.0019, -0.1002,  0.1515],\n",
            "        [-0.0999, -0.0994,  0.0206],\n",
            "        [-0.0990,  0.0285,  0.0921],\n",
            "        [ 0.0129,  0.1272,  0.0614],\n",
            "        [-0.1396, -0.1328,  0.0349],\n",
            "        [-0.1008, -0.0965, -0.0215],\n",
            "        [ 0.0957,  0.0833,  0.0849],\n",
            "        [ 0.0109,  0.1421,  0.1211],\n",
            "        [-0.1754, -0.1597,  0.0733],\n",
            "        [ 0.0299,  0.1514, -0.0707],\n",
            "        [-0.1422, -0.0861, -0.1132],\n",
            "        [ 0.0936,  0.1444, -0.0279],\n",
            "        [-0.1510, -0.0356,  0.0079],\n",
            "        [-0.0330, -0.0618,  0.0252],\n",
            "        [ 0.1147, -0.0780, -0.0412],\n",
            "        [-0.0767, -0.1759,  0.1679],\n",
            "        [ 0.1560,  0.0043, -0.0681],\n",
            "        [-0.0440,  0.0152, -0.1487],\n",
            "        [-0.0837, -0.0316, -0.0943],\n",
            "        [ 0.1026,  0.0430, -0.1713],\n",
            "        [ 0.0239, -0.0798,  0.1304],\n",
            "        [ 0.1287, -0.1264, -0.1354],\n",
            "        [-0.1504,  0.1295,  0.0882],\n",
            "        [ 0.1143, -0.0581, -0.0107],\n",
            "        [ 0.1066, -0.0263, -0.0714],\n",
            "        [ 0.0294, -0.1111,  0.0610],\n",
            "        [ 0.1638,  0.1328, -0.0559],\n",
            "        [-0.0462, -0.0055,  0.0290],\n",
            "        [-0.1747, -0.0872,  0.1017],\n",
            "        [-0.1109,  0.1442,  0.0714],\n",
            "        [-0.0088, -0.1371, -0.1473],\n",
            "        [ 0.0080,  0.0488, -0.1252],\n",
            "        [ 0.1314,  0.0280, -0.0073],\n",
            "        [-0.0190,  0.0064, -0.0878],\n",
            "        [ 0.0170, -0.0946,  0.1249],\n",
            "        [-0.1544, -0.1345,  0.1764],\n",
            "        [ 0.0523, -0.0955,  0.0030],\n",
            "        [ 0.1691,  0.0347, -0.0456],\n",
            "        [-0.1332,  0.0787, -0.1670],\n",
            "        [ 0.0529, -0.0787,  0.0442],\n",
            "        [-0.0649,  0.0234,  0.1273],\n",
            "        [-0.0605,  0.1351, -0.1273],\n",
            "        [ 0.1165, -0.0336,  0.0148],\n",
            "        [ 0.1450, -0.0278,  0.1373],\n",
            "        [ 0.1528, -0.0309, -0.0669],\n",
            "        [-0.0494,  0.1236,  0.0605],\n",
            "        [-0.0597,  0.0351, -0.0593],\n",
            "        [-0.0989, -0.1211,  0.0031],\n",
            "        [ 0.1180, -0.0868,  0.1156],\n",
            "        [ 0.1212,  0.1143, -0.1694],\n",
            "        [ 0.0724,  0.1759,  0.1057],\n",
            "        [-0.1315, -0.0876,  0.0394],\n",
            "        [-0.0598, -0.0312, -0.0809],\n",
            "        [ 0.0746, -0.0118, -0.0442],\n",
            "        [-0.0326, -0.0058,  0.0884],\n",
            "        [-0.1218, -0.0182, -0.0543],\n",
            "        [ 0.0317,  0.1319, -0.1101],\n",
            "        [-0.0454, -0.0009, -0.0484],\n",
            "        [ 0.1601,  0.1462, -0.0582],\n",
            "        [-0.0788, -0.0694, -0.0435],\n",
            "        [ 0.0593, -0.1187, -0.0075],\n",
            "        [ 0.0812, -0.0063,  0.1305],\n",
            "        [-0.0042, -0.1702, -0.1384],\n",
            "        [ 0.1136,  0.1144, -0.0874],\n",
            "        [-0.0316,  0.0307, -0.1340],\n",
            "        [-0.0843, -0.0406, -0.0179],\n",
            "        [ 0.1244,  0.0064, -0.0588],\n",
            "        [-0.0018, -0.0012, -0.1083],\n",
            "        [-0.1012, -0.0363, -0.0880],\n",
            "        [-0.0392, -0.0111, -0.1231],\n",
            "        [ 0.0482,  0.0517, -0.0339],\n",
            "        [ 0.0861,  0.0929,  0.0155],\n",
            "        [ 0.1597,  0.1659,  0.0119],\n",
            "        [ 0.1162,  0.1033, -0.1489],\n",
            "        [ 0.1465,  0.1448,  0.0605],\n",
            "        [ 0.1581, -0.0883, -0.0499],\n",
            "        [-0.0673, -0.1187, -0.1054],\n",
            "        [-0.1296,  0.1070,  0.0275],\n",
            "        [-0.0857,  0.0754, -0.0954],\n",
            "        [-0.1455, -0.0744,  0.1528],\n",
            "        [-0.1409, -0.1532,  0.1387],\n",
            "        [-0.1631,  0.1128,  0.0014],\n",
            "        [ 0.1424, -0.1763,  0.0216],\n",
            "        [ 0.1668, -0.1602, -0.1352],\n",
            "        [-0.0322, -0.1027, -0.0008],\n",
            "        [-0.1225,  0.1083, -0.0051],\n",
            "        [ 0.0936, -0.1255, -0.1704],\n",
            "        [-0.0882,  0.0513,  0.1330],\n",
            "        [-0.1453,  0.0084,  0.1135],\n",
            "        [-0.0304,  0.0732, -0.1647],\n",
            "        [-0.0073, -0.1111, -0.1330],\n",
            "        [ 0.1328,  0.1111, -0.1325],\n",
            "        [ 0.0870,  0.0906,  0.0005],\n",
            "        [ 0.0156,  0.1195,  0.0772],\n",
            "        [-0.0763,  0.0321,  0.1377],\n",
            "        [ 0.1629,  0.1212,  0.0461],\n",
            "        [ 0.1527, -0.0650, -0.1571],\n",
            "        [ 0.0354, -0.0081,  0.0081],\n",
            "        [-0.0650, -0.1191,  0.0038],\n",
            "        [-0.0850,  0.0573,  0.0917],\n",
            "        [ 0.0229,  0.0593, -0.1366],\n",
            "        [-0.0511, -0.1629,  0.0346],\n",
            "        [-0.1127,  0.0272,  0.1687],\n",
            "        [ 0.1085, -0.0227,  0.1046],\n",
            "        [-0.1714, -0.0642, -0.0270],\n",
            "        [-0.1660, -0.1039,  0.0614],\n",
            "        [-0.1353,  0.1188, -0.0187],\n",
            "        [ 0.0466,  0.1159, -0.1319],\n",
            "        [-0.0683, -0.0057, -0.0641],\n",
            "        [ 0.0414, -0.1628, -0.0727],\n",
            "        [-0.1699, -0.0450,  0.0162],\n",
            "        [ 0.0328,  0.0287,  0.0496],\n",
            "        [ 0.1667, -0.1413, -0.0981],\n",
            "        [ 0.1620, -0.0641,  0.1510],\n",
            "        [ 0.1518, -0.1375, -0.0957],\n",
            "        [ 0.0777, -0.1600,  0.0615],\n",
            "        [ 0.1374,  0.1338, -0.1757],\n",
            "        [ 0.0660,  0.0172,  0.0149],\n",
            "        [-0.0617,  0.1688, -0.1351],\n",
            "        [-0.0373, -0.0019,  0.0144],\n",
            "        [-0.0450,  0.1743, -0.1538],\n",
            "        [ 0.0041,  0.0216,  0.1630]], requires_grad=True)\n",
            "tensor(32.7134, grad_fn=<AddBackward0>)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0883,  0.0813,  0.1278,  ...,  0.1479,  0.1179, -0.0724],\n",
            "        [ 0.0943, -0.1573, -0.0009,  ..., -0.1248, -0.0756, -0.1599],\n",
            "        [-0.0545,  0.0482, -0.0294,  ...,  0.0471, -0.1403,  0.0580],\n",
            "        ...,\n",
            "        [-0.0915, -0.0134,  0.0915,  ..., -0.0318, -0.0542, -0.1220],\n",
            "        [ 0.0087,  0.1483, -0.0539,  ...,  0.1169,  0.0950, -0.0063],\n",
            "        [ 0.1018, -0.0014,  0.1160,  ...,  0.0864, -0.1287,  0.1396]],\n",
            "       requires_grad=True)\n",
            "tensor(395.6462, grad_fn=<AddBackward0>)\n",
            "Parameter containing:\n",
            "tensor([ 0.0813, -0.0415, -0.1726,  0.0331,  0.0954, -0.1738,  0.0885, -0.0408,\n",
            "        -0.1580,  0.0775,  0.0348,  0.0610, -0.1729, -0.0525, -0.0257, -0.0551,\n",
            "         0.1247, -0.0370,  0.0883,  0.0090,  0.1235,  0.0730,  0.0200,  0.0571,\n",
            "         0.0918,  0.0241, -0.1090,  0.0278,  0.1342, -0.0694,  0.1562,  0.1480,\n",
            "        -0.0205, -0.0093, -0.0287,  0.0541,  0.1138,  0.1089, -0.0294,  0.0624,\n",
            "        -0.1068,  0.1537,  0.0818, -0.0490, -0.0209, -0.1403, -0.1382, -0.1498,\n",
            "         0.0573,  0.1180, -0.1443, -0.0777, -0.0276,  0.0829, -0.0581, -0.0228,\n",
            "        -0.1451,  0.1609,  0.1131,  0.1534, -0.0199, -0.1364, -0.1607, -0.1601,\n",
            "         0.0772,  0.0298,  0.1158,  0.0682,  0.1174, -0.0291,  0.1156,  0.0761,\n",
            "        -0.0954,  0.1250,  0.0605,  0.1397,  0.1274,  0.0010,  0.0504, -0.1682,\n",
            "        -0.1095, -0.0994, -0.0666, -0.0811,  0.0731, -0.0437,  0.1194,  0.0904,\n",
            "        -0.0019,  0.0527,  0.1720, -0.1659, -0.1241, -0.0885,  0.1085, -0.1498,\n",
            "         0.1628,  0.0265,  0.0638,  0.1480, -0.1053,  0.1169,  0.1648,  0.0890,\n",
            "        -0.0699, -0.0538, -0.0460, -0.0716, -0.1366, -0.0293,  0.1584,  0.0563,\n",
            "         0.1385,  0.1214,  0.1689,  0.0901,  0.0874,  0.1355, -0.1517,  0.0106,\n",
            "        -0.0533, -0.0765, -0.0928,  0.0217, -0.0155, -0.0391,  0.1019, -0.0318],\n",
            "       requires_grad=True)\n",
            "tensor(406.9893, grad_fn=<AddBackward0>)\n",
            "Parameter containing:\n",
            "tensor([ 0.0996, -0.1337,  0.0183,  0.0923,  0.1069, -0.1618, -0.1243,  0.0850,\n",
            "        -0.1067, -0.0784, -0.1732, -0.1098,  0.0646, -0.0494, -0.0699,  0.0130,\n",
            "         0.1178, -0.0953,  0.1288,  0.0071, -0.0811,  0.0667,  0.0606, -0.1041,\n",
            "        -0.1458,  0.1631, -0.1395,  0.1125, -0.0856, -0.0720,  0.0760,  0.1286,\n",
            "         0.0214, -0.0130,  0.0505,  0.0958, -0.0223,  0.0461,  0.0070, -0.0027,\n",
            "        -0.1440,  0.1257,  0.1266, -0.1470, -0.0517,  0.0484,  0.0922,  0.1581,\n",
            "         0.0538, -0.0201,  0.1425, -0.0730,  0.1756,  0.0314,  0.1726, -0.0426,\n",
            "        -0.0262,  0.1359, -0.1100, -0.1224,  0.0146,  0.1305, -0.0488, -0.1635,\n",
            "        -0.1262,  0.0767, -0.1472, -0.1122,  0.1505,  0.1440,  0.0904, -0.1604,\n",
            "         0.1465, -0.0434,  0.1096,  0.1020,  0.0458,  0.0802, -0.0777, -0.1669,\n",
            "        -0.1646,  0.1700, -0.0339, -0.1671,  0.0357,  0.0596,  0.1175, -0.1019,\n",
            "         0.1585, -0.1079,  0.0704, -0.0704,  0.0453, -0.0330,  0.1650, -0.1137,\n",
            "        -0.0149, -0.1123,  0.0122,  0.0130, -0.0981, -0.0835, -0.0960, -0.1218,\n",
            "         0.1670,  0.1537, -0.0209, -0.1249,  0.0856,  0.0224, -0.0304, -0.0207,\n",
            "        -0.0443, -0.1212, -0.1682, -0.0331,  0.1554,  0.0833,  0.1594, -0.0265,\n",
            "        -0.1365, -0.1684, -0.0765, -0.0807, -0.0115, -0.1220,  0.0530,  0.0193],\n",
            "       requires_grad=True)\n",
            "tensor(418.7075, grad_fn=<AddBackward0>)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0181, -0.0772,  0.0266,  0.0580,  0.1515, -0.1356,  0.1588, -0.0340,\n",
            "          0.0542,  0.1409,  0.0170, -0.1336, -0.0617,  0.0974,  0.0862, -0.0124,\n",
            "         -0.0045, -0.0918,  0.1142, -0.0263, -0.1347,  0.0127, -0.1388, -0.0112,\n",
            "         -0.0945, -0.0746,  0.1039,  0.0751,  0.0544, -0.1270, -0.0287,  0.1236],\n",
            "        [-0.0984, -0.0511,  0.1160,  0.0865,  0.0243,  0.1636,  0.0198, -0.1649,\n",
            "          0.0941,  0.0815, -0.1767,  0.1069,  0.0720, -0.1361, -0.0389, -0.1763,\n",
            "          0.1164,  0.1516,  0.1750,  0.1491, -0.1177,  0.1597, -0.0906,  0.1052,\n",
            "          0.0367,  0.1114, -0.1201,  0.1085,  0.1432, -0.0255,  0.1163, -0.0848]],\n",
            "       requires_grad=True)\n",
            "tensor(424.6058, grad_fn=<AddBackward0>)\n",
            "Parameter containing:\n",
            "tensor([ 0.1363, -0.0684], requires_grad=True)\n",
            "tensor(424.8105, grad_fn=<AddBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = dataset.env # Reset environment\n",
        "env.reset(no_step=True)\n",
        "\n",
        "perf = 0 # Initialize loggin vars\n",
        "activity_dict = {}\n",
        "trial_infos = {}\n",
        "\n",
        "num_trial = 200\n",
        "for i in range(num_trial):\n",
        "\n",
        "    trial_info = env.new_trial() # New trial\n",
        "    ob, gt = env.ob, env.gt # Observation and groud-truth of this trial\n",
        "    inputs = torch.from_numpy(ob[:, np.newaxis, :]).type(torch.float)\n",
        "\n",
        "    action_pred, rnn_activity = net(inputs) # Run network for one trial\n",
        "\n",
        "    action_pred = action_pred.detach().numpy()[:, 0, :] # Compute performance\n",
        "    choice = np.argmax(action_pred[-1, :]) # Final choice at final time step\n",
        "    correct = choice == gt[-1]\n",
        "\n",
        "    rnn_activity = rnn_activity[:, 0, :].detach().numpy() # Record activity\n",
        "    activity_dict[i] = rnn_activity\n",
        "    trial_infos[i] = trial_info  # Record trial infos\n",
        "    trial_infos[i].update({'correct': correct})\n",
        "\n",
        "for i in range(20):\n",
        "    print('Trial ', i, trial_infos[i])\n",
        "\n",
        "print('Average performance', np.mean([val['correct'] for val in trial_infos.values()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWqjVx08i1Tj",
        "outputId": "474032fd-4c56-4e54-957b-561cc6d989c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial  0 {'measure': 800.0, 'gain': 2, 'production': 1600.0, 'correct': True}\n",
            "Trial  1 {'measure': 1000.0, 'gain': 2, 'production': 2000.0, 'correct': True}\n",
            "Trial  2 {'measure': 800.0, 'gain': 2, 'production': 1600.0, 'correct': True}\n",
            "Trial  3 {'measure': 1000.0, 'gain': 2, 'production': 2000.0, 'correct': True}\n",
            "Trial  4 {'measure': 800.0, 'gain': 2, 'production': 1600.0, 'correct': True}\n",
            "Trial  5 {'measure': 1200.0, 'gain': 2, 'production': 2400.0, 'correct': True}\n",
            "Trial  6 {'measure': 1000.0, 'gain': 2, 'production': 2000.0, 'correct': True}\n",
            "Trial  7 {'measure': 800.0, 'gain': 2, 'production': 1600.0, 'correct': True}\n",
            "Trial  8 {'measure': 1200.0, 'gain': 2, 'production': 2400.0, 'correct': True}\n",
            "Trial  9 {'measure': 1000.0, 'gain': 2, 'production': 2000.0, 'correct': True}\n",
            "Trial  10 {'measure': 1400.0, 'gain': 2, 'production': 2800.0, 'correct': True}\n",
            "Trial  11 {'measure': 1000.0, 'gain': 2, 'production': 2000.0, 'correct': True}\n",
            "Trial  12 {'measure': 1200.0, 'gain': 2, 'production': 2400.0, 'correct': True}\n",
            "Trial  13 {'measure': 1000.0, 'gain': 2, 'production': 2000.0, 'correct': True}\n",
            "Trial  14 {'measure': 1200.0, 'gain': 2, 'production': 2400.0, 'correct': True}\n",
            "Trial  15 {'measure': 1200.0, 'gain': 2, 'production': 2400.0, 'correct': True}\n",
            "Trial  16 {'measure': 800.0, 'gain': 2, 'production': 1600.0, 'correct': True}\n",
            "Trial  17 {'measure': 800.0, 'gain': 2, 'production': 1600.0, 'correct': True}\n",
            "Trial  18 {'measure': 1000.0, 'gain': 2, 'production': 2000.0, 'correct': True}\n",
            "Trial  19 {'measure': 1200.0, 'gain': 2, 'production': 2400.0, 'correct': True}\n",
            "Average performance 1.0\n"
          ]
        }
      ]
    }
  ]
}