{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsaGuOtiy+ezhbDLXT7ubk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adampotton/Cognitive_AI_CW/blob/main/Q2A_LSTM_BI_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adpating the LSTM model cost function to tackle sparsity"
      ],
      "metadata": {
        "id": "sXVSJrSC5bzt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/neurogym/neurogym.git\n",
        "%cd neurogym/\n",
        "! pip install -e ."
      ],
      "metadata": {
        "collapsed": true,
        "id": "3gn4uXo2PPtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4RPIsY6LowX",
        "outputId": "dc614ffb-492c-4abd-8dbf-5387ba561687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: Gym version v0.24.1 has a number of critical issues with `gym.make` such that environment observation and action spaces are incorrectly evaluated, raising incorrect errors and warning . It is recommend to downgrading to v0.23.1 or upgrading to v0.25.1\n",
            "/usr/local/lib/python3.10/dist-packages/gym/envs/registration.py:396: UserWarning: \u001b[33mWARN: The `registry.all` method is deprecated. Please use `registry.values` instead.\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ],
      "source": [
        "import neurogym as ngym\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define a simple LSTM model"
      ],
      "metadata": {
        "id": "5xqGhnoAk1Gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_lstm_layers = 2):\n",
        "        super(LSTMNet, self).__init__()\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_lstm_layers) # n LSTM layers\n",
        "        self.fc = nn.Linear(hidden_size, output_size) # Fully connected layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        lstm_output, _ = self.lstm(x)\n",
        "        out = self.fc(lstm_output)\n",
        "        return out, lstm_output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvUHo7Q4O0mZ",
        "outputId": "95ffdb5f-e9c9-4462-9a85-2eee6f50a95e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating dataset and adjusting parameters"
      ],
      "metadata": {
        "id": "1xE2ARNnlcXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\n",
        "    'dt': 200, # Timestep parameter\n",
        "    'hidden_size': 32, # Hidden size for your LSTM\n",
        "    'batch_size': 32, # Batch size for training\n",
        "    'seq_len': 50, # Sequence length for input data\n",
        "    'envid': 'ReadySetGo-v0', # Task name\n",
        "    'gain': 2, # Custom gain\n",
        "    'prod_margin': 10, # Custom production margin\n",
        "}\n",
        "\n",
        "env_kwargs = {\n",
        "    'dt': config['dt'], # Assing timestep parameter\n",
        "    'gain': config['gain'],  # Controls the measure that the agent has to produce\n",
        "    'prod_margin': config['prod_margin'], # Controls the interval around the ground truth production time within which the agent receives proportional reward\n",
        "}\n",
        "config['env_kwargs'] = env_kwargs\n",
        "\n",
        "dataset = ngym.Dataset(config['envid'], env_kwargs=config['env_kwargs'], batch_size=config['batch_size'], seq_len=config['seq_len']) # Generate dataset\n",
        "env = dataset.env\n",
        "\n",
        "inputs, target = dataset() # Assing inputs and targets\n",
        "inputs = torch.from_numpy(inputs).type(torch.float)\n",
        "\n",
        "input_size = env.observation_space.shape[0] # Find dimensions for data\n",
        "output_size = env.action_space.n\n",
        "\n",
        "print('Input has shape (SeqLen, Batch, Dim) =', inputs.shape)\n",
        "print('Target has shape (SeqLen, Batch) =', target.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kEqrXBuGlbO6",
        "outputId": "830f568f-1511-4df4-d1c9-136ac2c00f80"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input has shape (SeqLen, Batch, Dim) = torch.Size([50, 32, 3])\n",
            "Target has shape (SeqLen, Batch) = (50, 32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:69: UserWarning: \u001b[33mWARN: Agent's minimum action space value is -infinity. This is probably too low.\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:73: UserWarning: \u001b[33mWARN: Agent's maximum action space value is infinity. This is probably too high\u001b[0m\n",
            "  logger.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/gym/utils/passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
            "  logger.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model"
      ],
      "metadata": {
        "id": "77PBTEEOlxQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "iter_steps = 3000 # Training loops\n",
        "report_freq = 100 # How often a report on is returned\n",
        "l1_beta = 0.75 # Sparsity control\n",
        "\n",
        "net = LSTMNet(input_size, config['hidden_size'], output_size, num_lstm_layers = 2) # Create an instance of the LSTM\n",
        "\n",
        "def train_model(net, dataset, iter_steps, report_freq, l1_beta):\n",
        "\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.0003) # Adam optimiser\n",
        "    criterion = nn.CrossEntropyLoss() # Loss funciton\n",
        "\n",
        "    running_loss = 0\n",
        "    running_acc = 0\n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    start_time = time.time() # Start training timer\n",
        "\n",
        "    for i in range(iter_steps):  # Loop over training batches\n",
        "        inputs, labels = dataset()  # Generate a set of data\n",
        "        inputs = torch.from_numpy(inputs).type(torch.float)\n",
        "        labels = torch.from_numpy(labels.flatten()).type(torch.long)\n",
        "\n",
        "        optimizer.zero_grad()  # Reset gradients\n",
        "        output, _ = net(inputs)\n",
        "        output = output.view(-1, output_size)\n",
        "        loss = criterion(output, labels)  # Calculate loss\n",
        "\n",
        "\n",
        "        l1_reg = 0 # Initialise the L1 Regularisation term\n",
        "        for param in net.parameters(): # Extract all weight matrices from the network\n",
        "            if param.requires_grad: # ensure that regularisation is only applied to trainable parts of the model\n",
        "                l1_reg += torch.sum(torch.abs(param)) # Sum the matrices\n",
        "        loss = criterion(output, labels) + l1_beta * l1_reg # Define new modified loss funciton\n",
        "        loss.backward()\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        batch_acc = (torch.argmax(output, dim=1) == labels).sum().item() / labels.shape[0]  # Current batch accuracy\n",
        "        losses.append(loss.item())\n",
        "        accuracies.append(batch_acc)\n",
        "\n",
        "        if i % report_freq == report_freq - 1:\n",
        "            running_loss = sum(losses[-report_freq:]) / report_freq\n",
        "            running_acc = sum(accuracies[-report_freq:]) / report_freq\n",
        "            print('Step {}, Loss {:0.4f}, Accuracy {:0.4f}, Time {:0.1f}s'.format(\n",
        "                i + 1, running_loss, running_acc, time.time() - start_time))\n",
        "            running_loss = 0 # Reset metrics for next report\n",
        "            running_acc = 0\n",
        "    return net, losses, accuracies\n",
        "\n",
        "net, losses, accuracies = train_model(net, dataset, iter_steps, report_freq, l1_beta) # Call the training function"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "milzVKfVSmQT",
        "outputId": "737d0973-d78a-4942-c530-6924f6f88c3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 100, Loss 742.0802, Accuracy 0.9623, Time 2.3s\n",
            "Step 200, Loss 493.2041, Accuracy 0.9625, Time 4.1s\n",
            "Step 300, Loss 295.6466, Accuracy 0.9623, Time 6.8s\n",
            "Step 400, Loss 148.3761, Accuracy 0.9622, Time 8.7s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Measuring the sparsity"
      ],
      "metadata": {
        "id": "3fNAW3kCWX3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sparsity = 0\n",
        "total_params = 0\n",
        "for param in net.parameters():\n",
        "    if param.requires_grad:\n",
        "        total_params += param.numel()\n",
        "        sparsity += torch.sum(param <= 0.001).item()\n",
        "\n",
        "sparsity_ratio = sparsity / total_params\n",
        "print('Sparsity ratio:', sparsity_ratio)"
      ],
      "metadata": {
        "id": "T2lTaCuB6gfK",
        "outputId": "a3d7ac07-5bb4-4739-acc5-6e9615d66ab5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity ratio: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Peformance Metrics"
      ],
      "metadata": {
        "id": "a8eAE01F2ESX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_losses = []\n",
        "avg_accuracies = []\n",
        "report_freq = 20\n",
        "for i in range(report_freq - 1, len(losses), report_freq):\n",
        "    avg_losses.append(sum(losses[i-report_freq+1:i+1]) / report_freq)\n",
        "    avg_accuracies.append(sum(accuracies[i-report_freq+1:i+1]) / report_freq)\n",
        "\n",
        "iterations = range(report_freq, len(losses) + 1, report_freq)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['font.family'] = 'sans-serif'\n",
        "plt.rcParams['font.sans-serif'] = ['DejaVu Sans']\n",
        "\n",
        "# Plot Loss\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(iterations, avg_losses, label='Loss', color='blue')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Plot Accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(iterations, avg_accuracies, label='Accuracy', color='green')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim(0.8, 1.05)\n",
        "plt.title('Training Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Np1xonD42DXj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "outputId": "2398ddcf-2311-4975-ef3a-3168571eccd9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'losses' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-90ab16077ed3>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mavg_accuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreport_freq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport_freq\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mavg_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreport_freq\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mreport_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mavg_accuracies\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracies\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mreport_freq\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mreport_freq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = dataset.env # Reset environment\n",
        "env.reset(no_step=True)\n",
        "\n",
        "for i in range(500):\n",
        "    test_inputs, test_labels = dataset()\n",
        "    test_inputs = torch.from_numpy(test_inputs).type(torch.float)\n",
        "    test_labels = torch.from_numpy(test_labels.flatten()).type(torch.long)\n",
        "    test_accs = []\n",
        "    with torch.no_grad():\n",
        "        test_output, _ = net(test_inputs)\n",
        "        test_output = test_output.view(-1, output_size)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        test_loss = criterion(test_output, test_labels)\n",
        "        test_acc = (torch.argmax(test_output, dim=1) == test_labels).sum().item() / test_labels.shape[0]\n",
        "        test_accs.append(test_acc)\n",
        "\n",
        "print('Test Accuracy:', np.mean(test_accs))"
      ],
      "metadata": {
        "id": "FWqjVx08i1Tj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}